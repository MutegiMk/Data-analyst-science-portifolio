{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce27f50",
   "metadata": {},
   "source": [
    "## Ridge Regression is a popular type of regularized linear regression that includes an L2 penalty. This has the effect of shrinking the coefficients for those input variables that do not contribute much to the prediction task.\n",
    "\n",
    "### l2_penalty = sum j=0 to p beta_j^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bfea2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  price  \n",
      "0     15.3  396.90   4.98   24.0  \n",
      "1     17.8  396.90   9.14   21.6  \n",
      "2     17.8  392.83   4.03   34.7  \n",
      "3     18.7  394.63   2.94   33.4  \n",
      "4     18.7  396.90   5.33   36.2  \n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "house_pricing_dataset= sklearn.datasets.load_boston() \n",
    "#converting array into a dataframe and adding columns name\n",
    "house_pricing = pd.DataFrame(house_pricing_dataset.data,columns=house_pricing_dataset.feature_names)\n",
    "# add price column which is thetarget\n",
    "house_pricing['price']=house_pricing_dataset.target\n",
    "# shape of the dataset\n",
    "print(house_pricing.shape)\n",
    "# print the first 5 rows\n",
    "print(house_pricing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55e616",
   "metadata": {},
   "source": [
    "### The scikit-learn Python machine learning library provides an implementation of the Ridge Regression algorithm via the Ridge class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61ddc823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 3.382 (0.519)\n"
     ]
    }
   ],
   "source": [
    "# we are going to evaluate Ridge Regression model on the housing dataset using repeated 10-fold cross-validation\n",
    "data = house_pricing.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# define model\n",
    "model = Ridge(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a05611",
   "metadata": {},
   "source": [
    "### Let use the Ridge Regression as our final model and make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3ca6b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 30.456\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y)\n",
    "# define new data\n",
    "row = [0.00642,19.00,2.320,0,0.5381,6.5750,64.20,4.0910,1,286.0,15.30,399.90,4.99]\n",
    "# make a prediction\n",
    "predictions = model.predict([row])\n",
    "# summarize prediction\n",
    "print('Predicted: %.3f' % predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab8e88",
   "metadata": {},
   "source": [
    "### Tuning Ridge Hyperparameters\n",
    "It is hard know if the default hyperparameters of alpha=1.0 is appropriate for our dataset so Instead, it is good practice to test a suite of different configurations and discover what works best for our dataset.\n",
    "\n",
    "One approach would be to grid search alpha values from perhaps 1e-5 to 100 on a log scale and discover what works best for a dataset. Another approach would be to test values between 0.0 and 1.0 with a grid separation of 0.01. We will try the latter in this case.\n",
    "\n",
    "The work below demonstrates this using the GridSearchCV class with a grid of values I have defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b9a1b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -3.379\n",
      "Config: {'alpha': 0.51}\n",
      " The negative  comes as a results of the library assigning MAE negative for optimization purposes.\n",
      "Also the model assigned an alpha weight of 0.51 to the penalty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import arange\n",
    "model = Ridge()\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# defining grid\n",
    "grid = dict()\n",
    "grid['alpha'] = arange(0, 1, 0.01)\n",
    "# defining search\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "print(\"\"\" The negative  comes as a results of the library assigning MAE negative for optimization purposes.\n",
    "Also the model assigned an alpha weight of 0.51 to the penalty.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2a4df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
